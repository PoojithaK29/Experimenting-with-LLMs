{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query transformation using HyDE for efficient retrieval\n",
    "#Traditional approaches lag between short queries and long queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothetical Document Embedding (HyDE) \n",
    "\n",
    "Introduction\n",
    "\n",
    "In the rapidly evolving field of document retrieval, accurately matching user queries to relevant documents is a critical challenge. Traditional retrieval methods often face difficulties in bridging the semantic gap between concise queries and more expansive documents. The Hypothetical Document Embedding (HyDE) approach is a novel solution designed to address this issue by transforming queries into detailed hypothetical documents that better align with document representations in vector space. This article explores the intricacies of the HyDE approach, its motivation, key components, and potential impact on document retrieval.\n",
    "\n",
    "Motivation\n",
    "\n",
    "The primary motivation behind HyDE lies in the inherent limitations of traditional retrieval methods. Conventional approaches, such as TF-IDF, BM25, and even some advanced neural models, often struggle with the disparity between short, often ambiguous queries and the rich, detailed information contained in documents. This semantic gap can result in less relevant retrieval outcomes, as the query representation may not effectively capture the nuances of the target documents.\n",
    "To address this, HyDE introduces a novel strategy: rather than directly comparing the query with the documents, it first expands the query into a hypothetical document that hypothesizes the content that might contain the answer. By doing so, HyDE aligns the query more closely with the document representations in the vector space, potentially improving the relevance and accuracy of retrieval results.\n",
    "\n",
    "How HyDE Works: An In-Depth Look\n",
    "\n",
    "The HyDE approach can be broken down into several key components that work in tandem to enhance document retrieval:\n",
    "\n",
    "1. Query Expansion through Hypothetical Documents\n",
    "\n",
    "At the core of HyDE is the concept of transforming a query into a hypothetical document. Given a user query, a language model generates a detailed document that hypothetically contains the answer or information relevant to the query. This document isn't retrieved from any existing database but is synthesized on-the-fly, based on the query's context. The goal is to create a representation that is more semantically rich and comprehensive than the original query.\n",
    "For example, if the query is \"benefits of renewable energy,\" the hypothetical document generated by the language model might elaborate on various types of renewable energy, their environmental impact, economic benefits, and policy implications. This expansion allows the query to be represented in a manner more akin to the structure and content of actual documents in the database.\n",
    "\n",
    "2. Vector Embedding and Similarity Calculation\n",
    "\n",
    "Once the hypothetical document is generated, it is embedded into a vector space using advanced embeddings such as those provided by language models. These embeddings are designed to capture the semantic meaning of the text, translating the hypothetical document into a multi-dimensional vector that represents its content in a way that can be mathematically compared with other documents.\n",
    "Documents in the database are similarly embedded into the vector space, using the same embedding technique. The HyDE approach then involves calculating the similarity between the query's hypothetical document vector and the vectors of actual documents in the database. Techniques like FAISS (Facebook AI Similarity Search) , cosine similarity or others are often employed to efficiently manage and search through large collections of vectors, ensuring that the most relevant documents are retrieved based on their proximity to the query vector.\n",
    "\n",
    "3. PDF Processing and Text Chunking\n",
    "\n",
    "In real-world applications, documents often come in various formats, including PDFs, which are commonly used in academic, legal, and business environments. HyDE systems need to preprocess these documents by extracting text and chunking it into manageable segments that can be embedded into vector space.\n",
    "Text chunking involves breaking down large documents into smaller, coherent pieces that can be independently analyzed and compared. This step is crucial because it allows the system to maintain the context of the information while enabling efficient retrieval processes. By chunking text and processing it into vectors, HyDE ensures that even specific sections of a document that may be relevant to a query are not overlooked.\n",
    "\n",
    "Advantages of HyDE\n",
    "\n",
    "The Hypothetical Document Embedding approach offers several significant advantages over traditional document retrieval methods:\n",
    "Enhanced Relevance: By transforming queries into detailed hypothetical documents, HyDE reduces the semantic gap, leading to more relevant retrieval results.\n",
    "Better Query-Document Alignment: The expanded query representation is more likely to align with the structure and content of the documents in the database, improving the accuracy of the retrieval process.\n",
    "Flexibility: HyDE can be adapted to various types of queries and document formats, making it versatile for different applications.\n",
    "Efficiency in Large-Scale Retrieval: By leveraging vector-based retrieval techniques, HyDE ensures that even in large document collections, the most relevant results can be retrieved quickly and efficiently.\n",
    "\n",
    "Challenges and Future Directions\n",
    "\n",
    "While HyDE presents a promising approach to improving document retrieval, it is not without challenges. The quality of the hypothetical documents generated by the language model plays a critical role in the overall effectiveness of the system. Poorly generated documents can lead to irrelevant or misleading retrieval results. Therefore, ongoing research into refining language models and embedding techniques is essential.\n",
    "Future developments in HyDE may focus on incorporating feedback mechanisms, where the system learns from user interactions to improve the quality of hypothetical documents and retrieval results over time. Additionally, integrating HyDE with more specialized domain-specific models could enhance its applicability in fields such as medicine, law, and finance.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The Hypothetical Document Embedding (HyDE) approach represents a significant step forward in the field of document retrieval. By bridging the gap between short queries and detailed documents through the creation of hypothetical documents, HyDE offers a more aligned and semantically rich retrieval process. As this approach continues to evolve, it has the potential to revolutionize how information is accessed and utilized across various domains, making it a powerful tool for anyone seeking to improve the relevance and accuracy of document retrieval systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define document path\n",
    "path = \"sample.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyDERetriever:\n",
    "    def __init__(self, files_path, chunk_size=500, chunk_overlap=100):\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
    "\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.vectorstore = encode_pdf(files_path, chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "    \n",
    "        \n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"chunk_size\"],\n",
    "            template=\"\"\"Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
    "            the document size has be exactly {chunk_size} characters.\"\"\",\n",
    "        )\n",
    "        self.hyde_chain = self.hyde_prompt | self.llm\n",
    "\n",
    "    def generate_hypothetical_document(self, query):\n",
    "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
    "        return self.hyde_chain.invoke(input_variables).content\n",
    "\n",
    "    def retrieve(self, query, k=3):\n",
    "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "        similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
    "        return similar_docs, hypothetical_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is lmu?\"\n",
    "results, hypothetical_doc = retriever.retrieve(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_content = [doc.page_content for doc in results]\n",
    "\n",
    "print(\"hypothetical_doc:\\n\")\n",
    "print(text_wrap(hypothetical_doc)+\"\\n\")\n",
    "show_context(docs_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
