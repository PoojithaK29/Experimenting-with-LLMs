{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sub-query Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Sub-query Decomposition?**\n",
    "\n",
    "Sub-query decomposition is a technique used in Retrieval-Augmented Generation (RAG) systems to break down complex queries into simpler, more manageable sub-queries. This approach helps in retrieving more comprehensive information by addressing different aspects of a complex query. By decomposing a complex query into smaller parts, each sub-query can be answered separately, and the combined responses provide a thorough answer to the original query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps to Create Sub-query Decomposition**\n",
    "\n",
    "**Define the Original Complex Query:** Start with a complex query that covers multiple aspects or dimensions of a topic.\n",
    "\n",
    "**Decompose the Query:** Break down the original query into 2-4 simpler sub-queries that, when answered together, provide a complete and detailed response.\n",
    "\n",
    "**Generate Responses:** Each sub-query is then used to retrieve specific information, and the combined responses offer a comprehensive answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Initialize the local model\n",
    "sub_query_llm = ollama.chat(model='llama3')\n",
    "\n",
    "# Create a prompt template for sub-query decomposition\n",
    "subquery_decomposition_template = \"\"\"You are an AI assistant tasked with breaking down complex queries into simpler sub-queries for a RAG system.\n",
    "Given the original query, decompose it into 2-4 simpler sub-queries that, when answered together, would provide a comprehensive response to the original query.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "example: What are the impacts of climate change on the environment?\n",
    "\n",
    "Sub-queries:\n",
    "1. What are the impacts of climate change on biodiversity?\n",
    "2. How does climate change affect the oceans?\n",
    "3. What are the effects of climate change on agriculture?\n",
    "4. What are the impacts of climate change on human health?\"\"\"\n",
    "\n",
    "subquery_decomposition_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=subquery_decomposition_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for sub-query decomposition\n",
    "subquery_decomposer_chain = LLMChain(\n",
    "    prompt=subquery_decomposition_prompt,\n",
    "    llm=sub_query_llm\n",
    ")\n",
    "\n",
    "def decompose_query(original_query: str):\n",
    "    \"\"\"\n",
    "    Decompose the original query into simpler sub-queries.\n",
    "    \n",
    "    Args:\n",
    "    original_query (str): The original complex query\n",
    "    \n",
    "    Returns:\n",
    "    List[str]: A list of simpler sub-queries\n",
    "    \"\"\"\n",
    "    response = subquery_decomposer_chain.run(original_query)\n",
    "    sub_queries = [q.strip() for q in response.split('\\n') if q.strip() and not q.strip().startswith('Sub-queries:')]\n",
    "    return sub_queries\n",
    "\n",
    "# Demonstrate on a use case\n",
    "original_query = \"What is generative AI?\"\n",
    "sub_queries = decompose_query(original_query)\n",
    "print(\"\\nSub-queries:\")\n",
    "for i, sub_query in enumerate(sub_queries, 1):\n",
    "    print(sub_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original Query:** \"What is generative AI?\"\n",
    "\n",
    "**Sub-queries:**\n",
    "\n",
    "What are the fundamental principles and mechanisms that define generative AI?\n",
    "How does generative AI differ from traditional AI approaches?\n",
    "What are some common applications and examples of generative AI in various industries?\n",
    "What are the key challenges and ethical considerations associated with generative AI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advantages and Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#Advantages of Sub-query Decomposition**\n",
    "\n",
    "**Comprehensive Coverage:** By breaking down a complex query, sub-query decomposition ensures that all aspects of the original query are addressed, leading to a more complete response.\n",
    "\n",
    "**Improved Retrieval:** Simpler sub-queries are often easier to match with relevant documents, improving the precision and recall of the retrieved information.\n",
    "\n",
    "**Modular Answers:** Each sub-query can be answered independently, allowing for modular and more focused retrieval and generation of responses.\n",
    "\n",
    "**#Limitations of Sub-query Decomposition**\n",
    "\n",
    "**Complexity in Implementation:** Implementing sub-query decomposition requires careful design and understanding of how to effectively break down a query.\n",
    "\n",
    "**Increased Processing Time:** Decomposing a query into multiple sub-queries and processing each one separately can increase the overall time required to generate a response.\n",
    "\n",
    "**Potential Over-simplification:** In some cases, breaking down a query might lead to the loss of context or nuances present in the original complex query, resulting in less accurate answers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
